{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from VQ_model import get_model\n",
    "from diffusion_model import VQ_diffwave\n",
    "import params as params\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vq_model = get_model(data_variance = None, inference = True)\n",
    "vq_model.load_state_dict(torch.load('VQ_pth/model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80000])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    wav, sr = torchaudio.load('../dataset/ESC-50-master/audio/1-103298-A-9.wav')\n",
    "    wav = torchaudio.transforms.Resample(sr, 16000)(wav)\n",
    "    wav = wav.unsqueeze(1)\n",
    "    z = vq_model(wav)\n",
    "    output = vq_model.decoder(z)\n",
    "    sample = output.squeeze(0)\n",
    "    print(sample.shape)\n",
    "    sample_wav = torchaudio.save('sample.wav', sample.cpu(), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.8222e+03, 1.0867e+01, 7.5818e+02,  ..., 1.3297e+01,\n",
       "          5.5233e-02, 6.7544e+01],\n",
       "         [1.0959e+03, 1.0555e+02, 4.2179e+02,  ..., 2.0232e+01,\n",
       "          3.2413e+01, 5.9449e+01],\n",
       "         [2.8181e+02, 8.9268e+00, 2.1007e+01,  ..., 1.0755e+01,\n",
       "          2.6052e+01, 1.3188e+01],\n",
       "         ...,\n",
       "         [1.1023e-04, 1.3692e-08, 1.5618e-08,  ..., 1.1548e-08,\n",
       "          3.1744e-08, 1.6095e-07],\n",
       "         [1.1238e-04, 8.0217e-10, 2.6339e-09,  ..., 1.1182e-08,\n",
       "          1.3706e-08, 9.6164e-08],\n",
       "         [1.1409e-04, 4.1746e-09, 5.6762e-09,  ..., 6.7462e-09,\n",
       "          5.7199e-12, 2.0327e-08]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav, sr = torchaudio.load('sample_test.wav')\n",
    "spec = torchaudio.transforms.Spectrogram()(wav)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
